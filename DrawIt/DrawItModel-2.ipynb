{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrawItModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UIqsIYOVJTQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4cCSQepHHhe",
        "colab_type": "code",
        "outputId": "8ba8b359-9465-423a-b8d7-abe7d0537888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/pocahontasabi/Ml_b/master/DrawIt/classes.txt'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-02 11:11:57--  https://raw.githubusercontent.com/pocahontasabi/Ml_b/master/DrawIt/classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 759 [text/plain]\n",
            "Saving to: ‘classes.txt’\n",
            "\n",
            "\rclasses.txt           0%[                    ]       0  --.-KB/s               \rclasses.txt         100%[===================>]     759  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-02 11:11:57 (66.8 MB/s) - ‘classes.txt’ saved [759/759]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SwL_JR7VH4k1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open(\"classes.txt\",\"r\")   #file with 100 classes from quick draw\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NqTeQwiQIFwp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ua9FFgw_IITM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data #download data from googleapi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWtJzBz2IO3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOnqD0_5IYvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1cLOtWwfKMLZ",
        "colab_type": "code",
        "outputId": "8bd320f8-4b3a-4d4a-b11e-260b92e72f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "download()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpoUQ_TyJt3h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7MOYl5UfJ7Hu",
        "colab_type": "code",
        "outputId": "497e607f-51df-42e2-c702-a6f2da282531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "akrfu0gjJ9RL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4DZ_bjteN-0m",
        "colab_type": "code",
        "outputId": "a1c5ed6a-5fb2-4540-dfbe-f40278ea7714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 110,052\n",
            "Trainable params: 110,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "htyPFYF6N-8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "4c2bad52-94e8-4c35-a70d-795344397307"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 288000 samples, validate on 32000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            " - 26s - loss: 1.9194 - top_k_categorical_accuracy: 0.7811 - val_loss: 1.3377 - val_top_k_categorical_accuracy: 0.8828\n",
            "Epoch 2/5\n",
            " - 13s - loss: 1.2388 - top_k_categorical_accuracy: 0.8939 - val_loss: 1.1671 - val_top_k_categorical_accuracy: 0.9014\n",
            "Epoch 3/5\n",
            " - 8s - loss: 1.0864 - top_k_categorical_accuracy: 0.9102 - val_loss: 1.0720 - val_top_k_categorical_accuracy: 0.9110\n",
            "Epoch 4/5\n",
            " - 14s - loss: 0.9989 - top_k_categorical_accuracy: 0.9191 - val_loss: 0.9847 - val_top_k_categorical_accuracy: 0.9197\n",
            "Epoch 5/5\n",
            " - 23s - loss: 0.9406 - top_k_categorical_accuracy: 0.9252 - val_loss: 0.9615 - val_top_k_categorical_accuracy: 0.9218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7a53120fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "CbOCaTkQN---",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ee55910-8de2-4b02-b62d-8d81d065a9eb"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 92.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3U-K44ujN_Be",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "c791bb31-4dfa-4f1d-f853-61233cb2b776"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[0]\n",
        "latex = class_names[ind]\n",
        "print(latex)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anvil\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSBThBxJF+IFEEX4gUYQfSNT/A2S8Soai0iWvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "33JpJRLsN_J_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qDlGI5mPS2ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ebaba63c-b349-4feb-e62c-1011a4be538e"
      },
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "44s45r0QSauI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e4bbece1-a89c-478c-9147-8511972c94c7"
      },
      "cell_type": "code",
      "source": [
        "pip install coremltools"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: coremltools in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.16.3)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->coremltools) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fsnl6BO_TOSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import keras\n",
        "import coremltools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2cf023e8-a3c2-4bbd-fe06-f69b23e4bcf5",
        "id": "0RuhWXnoWOUj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.utils import CustomObjectScope\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
        "        model = load_model('model.h5')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HY6U1ACcVkyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "ad40b690-485d-4773-e33e-a27d6f683909"
      },
      "cell_type": "code",
      "source": [
        "coreml_model = coremltools.converters.keras.convert(model)\n",
        "coreml_model.save('my_model.mlmodel')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : conv2d_input, <keras.engine.input_layer.InputLayer object at 0x7f79f52d8a58>\n",
            "1 : conv2d, <keras.layers.convolutional.Conv2D object at 0x7f79f52d8898>\n",
            "2 : conv2d__activation__, <keras.layers.core.Activation object at 0x7f79f519b128>\n",
            "3 : max_pooling2d, <keras.layers.pooling.MaxPooling2D object at 0x7f79f52d8ac8>\n",
            "4 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x7f79f5244a90>\n",
            "5 : conv2d_1__activation__, <keras.layers.core.Activation object at 0x7f79f5186128>\n",
            "6 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x7f79f5342c18>\n",
            "7 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x7f79f52d8e48>\n",
            "8 : conv2d_2__activation__, <keras.layers.core.Activation object at 0x7f79f52fe668>\n",
            "9 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x7f79f5206630>\n",
            "10 : flatten, <keras.layers.core.Flatten object at 0x7f79f53429b0>\n",
            "11 : dense, <keras.layers.core.Dense object at 0x7f79f51af198>\n",
            "12 : dense__activation__, <keras.layers.core.Activation object at 0x7f79f52fe978>\n",
            "13 : dense_1, <keras.layers.core.Dense object at 0x7f79f51ca3c8>\n",
            "14 : dense_1__activation__, <keras.layers.core.Activation object at 0x7f79f52fe898>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BmlRhUp4T7KS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QhkDgOvW9td",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "ee72dc00-e685-42c6-ec4b-ac0c447d6652"
      },
      "cell_type": "code",
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tGLPZd6jXEuV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtzRpRe_XKYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}